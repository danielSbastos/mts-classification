{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5d7fb8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro as stats_shapiro\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e11252a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['juliana-ab', 'juliana-svm', 'juliana-dt', 'juliana-rf', 'juliana-gb', 'juliana-knn', 'juliana-mlp']\n",
    "#models = ['juliana-rf', 'juliana-svm', 'juliana-mlp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9ff5b63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_folder_n(label, fold_no=10):\n",
    "    f1_scores = []\n",
    "    accuracies = []\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for n in range(15):\n",
    "        predictions = []\n",
    "        labels = []\n",
    "        for i in range(1, fold_no + 1):\n",
    "            with open('results/' + label + '/' + str(n) + '/' + str(i) + '-predicted.txt', 'r') as file:\n",
    "                for _predictions in file.readlines():\n",
    "                    predictions += list(_predictions)[:-1]\n",
    "                    \n",
    "            with open('results/' + label + '/' + str(n) + '/' + str(i) + '-label.txt', 'r') as file:\n",
    "                for _labels in file.readlines():\n",
    "                    labels += list(_labels)[:-1]\n",
    "                    \n",
    "        all_predictions += predictions            \n",
    "        all_labels += labels            \n",
    "        f1_scores.append(f1_score(labels, predictions, average='weighted'))\n",
    "        accuracies.append(accuracy_score(labels, predictions))\n",
    "    \n",
    "    print(classification_report(all_labels, all_predictions))\n",
    "    return f1_scores, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "20b2d732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shapiro(model):\n",
    "    print(\"====> Shapiro-Wilk for \" + model)\n",
    "    f1_scores, accuracies = report_folder_n(model)\n",
    "    p_value_f1 = stats_shapiro(f1_scores)[1]\n",
    "    p_value_accuracy = stats_shapiro(accuracies)[1]\n",
    "    \n",
    "    print(\"    p-value F1-score: \" + str(p_value_f1), end=\" \")\n",
    "    if p_value_f1 < 0.05:\n",
    "        print(\"not gaussian\")\n",
    "    else:\n",
    "        print(\"gaussian\")\n",
    "        \n",
    "    print(\"    p-value Accuracy: \" + str(p_value_accuracy), end=\" \")\n",
    "    if p_value_accuracy < 0.05:\n",
    "        print(\"not gaussian\\n\")\n",
    "    else:\n",
    "        print(\"gaussian\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0db6f36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Shapiro-Wilk for juliana-ab\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.61      0.34       855\n",
      "           1       0.64      0.41      0.50     23055\n",
      "           2       0.43      0.51      0.46     14415\n",
      "           3       0.39      0.30      0.34     12945\n",
      "           4       0.09      0.51      0.15      1440\n",
      "\n",
      "    accuracy                           0.42     52710\n",
      "   macro avg       0.36      0.47      0.36     52710\n",
      "weighted avg       0.50      0.42      0.44     52710\n",
      "\n",
      "    p-value F1-score: 0.18772399425506592 gaussian\n",
      "    p-value Accuracy: 0.30482861399650574 gaussian\n",
      "\n",
      "====> Shapiro-Wilk for juliana-svm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.42      0.58       855\n",
      "           1       0.61      0.94      0.74     23055\n",
      "           2       0.90      0.55      0.68     14415\n",
      "           3       0.82      0.48      0.61     12945\n",
      "           4       0.33      0.10      0.15      1440\n",
      "\n",
      "    accuracy                           0.69     52710\n",
      "   macro avg       0.72      0.50      0.55     52710\n",
      "weighted avg       0.74      0.69      0.67     52710\n",
      "\n",
      "    p-value F1-score: 0.32283326983451843 gaussian\n",
      "    p-value Accuracy: 0.5329688191413879 gaussian\n",
      "\n",
      "====> Shapiro-Wilk for juliana-dt\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.76      0.62       855\n",
      "           1       0.82      0.72      0.77     23055\n",
      "           2       0.69      0.76      0.72     14415\n",
      "           3       0.70      0.65      0.68     12945\n",
      "           4       0.21      0.46      0.29      1440\n",
      "\n",
      "    accuracy                           0.71     52710\n",
      "   macro avg       0.59      0.67      0.62     52710\n",
      "weighted avg       0.73      0.71      0.72     52710\n",
      "\n",
      "    p-value F1-score: 0.5072422623634338 gaussian\n",
      "    p-value Accuracy: 0.400658518075943 gaussian\n",
      "\n",
      "====> Shapiro-Wilk for juliana-rf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80       855\n",
      "           1       0.87      0.86      0.87     23055\n",
      "           2       0.86      0.84      0.85     14415\n",
      "           3       0.77      0.79      0.78     12945\n",
      "           4       0.41      0.51      0.46      1440\n",
      "\n",
      "    accuracy                           0.83     52710\n",
      "   macro avg       0.75      0.76      0.75     52710\n",
      "weighted avg       0.83      0.83      0.83     52710\n",
      "\n",
      "    p-value F1-score: 0.7010366320610046 gaussian\n",
      "    p-value Accuracy: 0.7572941780090332 gaussian\n",
      "\n",
      "====> Shapiro-Wilk for juliana-gb\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.71      0.75       855\n",
      "           1       0.88      0.87      0.87     23055\n",
      "           2       0.84      0.84      0.84     14415\n",
      "           3       0.77      0.78      0.77     12945\n",
      "           4       0.42      0.50      0.46      1440\n",
      "\n",
      "    accuracy                           0.83     52710\n",
      "   macro avg       0.74      0.74      0.74     52710\n",
      "weighted avg       0.83      0.83      0.83     52710\n",
      "\n",
      "    p-value F1-score: 1.904447458400682e-06 not gaussian\n",
      "    p-value Accuracy: 1.4564349157808465e-06 not gaussian\n",
      "\n",
      "====> Shapiro-Wilk for juliana-knn\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.83      0.53       855\n",
      "           1       0.84      0.77      0.80     23055\n",
      "           2       0.77      0.72      0.74     14415\n",
      "           3       0.70      0.65      0.67     12945\n",
      "           4       0.21      0.62      0.32      1440\n",
      "\n",
      "    accuracy                           0.72     52710\n",
      "   macro avg       0.58      0.72      0.61     52710\n",
      "weighted avg       0.76      0.72      0.74     52710\n",
      "\n",
      "    p-value F1-score: 0.343470960855484 gaussian\n",
      "    p-value Accuracy: 0.8755550384521484 gaussian\n",
      "\n",
      "====> Shapiro-Wilk for juliana-mlp\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76       855\n",
      "           1       0.88      0.81      0.84     23055\n",
      "           2       0.82      0.79      0.81     14415\n",
      "           3       0.71      0.74      0.73     12945\n",
      "           4       0.27      0.55      0.36      1440\n",
      "\n",
      "    accuracy                           0.78     52710\n",
      "   macro avg       0.68      0.74      0.70     52710\n",
      "weighted avg       0.80      0.78      0.79     52710\n",
      "\n",
      "    p-value F1-score: 0.8411683440208435 gaussian\n",
      "    p-value Accuracy: 0.8745509386062622 gaussian\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(shapiro, models))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
