{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d7fb8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro as stats_shapiro, kruskal as stats_kruskal\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "147033a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikit_posthocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e11252a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['juliana-ab', 'juliana-svm', 'juliana-dt', 'juliana-rf', 'juliana-gb', 'juliana-knn', 'juliana-mlp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ff5b63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_folder_n(label, fold_no=10):\n",
    "    f1_scores = []\n",
    "    accuracies = []\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for n in range(15):\n",
    "        predictions = []\n",
    "        labels = []\n",
    "        for i in range(1, fold_no + 1):\n",
    "            with open('results/' + label + '/' + str(n) + '/' + str(i) + '-predicted.txt', 'r') as file:\n",
    "                for _predictions in file.readlines():\n",
    "                    predictions += list(_predictions)[:-1]\n",
    "                    \n",
    "            with open('results/' + label + '/' + str(n) + '/' + str(i) + '-label.txt', 'r') as file:\n",
    "                for _labels in file.readlines():\n",
    "                    labels += list(_labels)[:-1]\n",
    "                    \n",
    "        all_predictions += predictions            \n",
    "        all_labels += labels           \n",
    "        f1_scores.append(f1_score(labels, predictions, average='weighted'))\n",
    "        accuracies.append(accuracy_score(labels, predictions))\n",
    "    \n",
    "    #print(classification_report(all_labels, all_predictions))\n",
    "    return f1_scores, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20b2d732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shapiro(model):\n",
    "    print(\"====> Shapiro-Wilk for \" + model)\n",
    "    f1_scores, accuracies = report_folder_n(model)\n",
    "    p_value_f1 = stats_shapiro(f1_scores)[1]\n",
    "    p_value_accuracy = stats_shapiro(accuracies)[1]\n",
    "    \n",
    "    print(\"    p-value F1-score: \" + str(p_value_f1), end=\" \")\n",
    "    if p_value_f1 < 0.05:\n",
    "        print(\"not gaussian\")\n",
    "    else:\n",
    "        print(\"gaussian\")\n",
    "        \n",
    "    print(\"    p-value Accuracy: \" + str(p_value_accuracy), end=\" \")\n",
    "    if p_value_accuracy < 0.05:\n",
    "        print(\"not gaussian\\n\")\n",
    "    else:\n",
    "        print(\"gaussian\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0db6f36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Shapiro-Wilk for juliana-ab\n",
      "    p-value F1-score: 0.18772399425506592 gaussian\n",
      "    p-value Accuracy: 0.30482861399650574 gaussian\n",
      "\n",
      "====> Shapiro-Wilk for juliana-svm\n",
      "    p-value F1-score: 0.32283326983451843 gaussian\n",
      "    p-value Accuracy: 0.5329688191413879 gaussian\n",
      "\n",
      "====> Shapiro-Wilk for juliana-dt\n",
      "    p-value F1-score: 0.5072422623634338 gaussian\n",
      "    p-value Accuracy: 0.400658518075943 gaussian\n",
      "\n",
      "====> Shapiro-Wilk for juliana-rf\n",
      "    p-value F1-score: 0.7010366320610046 gaussian\n",
      "    p-value Accuracy: 0.7572941780090332 gaussian\n",
      "\n",
      "====> Shapiro-Wilk for juliana-gb\n",
      "    p-value F1-score: 1.904447458400682e-06 not gaussian\n",
      "    p-value Accuracy: 1.4564349157808465e-06 not gaussian\n",
      "\n",
      "====> Shapiro-Wilk for juliana-knn\n",
      "    p-value F1-score: 0.343470960855484 gaussian\n",
      "    p-value Accuracy: 0.8755550384521484 gaussian\n",
      "\n",
      "====> Shapiro-Wilk for juliana-mlp\n",
      "    p-value F1-score: 0.8411683440208435 gaussian\n",
      "    p-value Accuracy: 0.8745509386062622 gaussian\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(shapiro, models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6bbd5d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KruskalResult(statistic=99.37308176100635, pvalue=3.3910468756000684e-19) KruskalResult(statistic=99.23905480245028, pvalue=3.6165018378640245e-19)\n"
     ]
    }
   ],
   "source": [
    "results = list(map(report_folder_n, models))\n",
    "f1_scores = list(map(lambda x: x[0], results))\n",
    "accuracies = list(map(lambda x: x[1], results))\n",
    "f1_kruskal = stats_kruskal(*f1_scores)\n",
    "acc_kruskal = stats_kruskal(*accuracies)\n",
    "print(f1_kruskal, acc_kruskal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0252911c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrr}\n",
      " & 1 & 2 & 3 & 4 & 5 & 6 & 7 \\\\\n",
      "1 & 1.000000 & 0.983400 & 0.136800 & 0.000000 & 0.000000 & 0.001100 & 0.000000 \\\\\n",
      "2 & 0.983400 & 1.000000 & 0.983400 & 0.000000 & 0.000000 & 0.136800 & 0.000700 \\\\\n",
      "3 & 0.136800 & 0.983400 & 1.000000 & 0.000100 & 0.000000 & 0.983400 & 0.105800 \\\\\n",
      "4 & 0.000000 & 0.000000 & 0.000100 & 1.000000 & 1.000000 & 0.021600 & 0.760000 \\\\\n",
      "5 & 0.000000 & 0.000000 & 0.000000 & 1.000000 & 1.000000 & 0.015400 & 0.680100 \\\\\n",
      "6 & 0.001100 & 0.136800 & 0.983400 & 0.021600 & 0.015400 & 1.000000 & 0.967200 \\\\\n",
      "7 & 0.000000 & 0.000700 & 0.105800 & 0.760000 & 0.680100 & 0.967200 & 1.000000 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f1_df = scikit_posthocs.posthoc_dunn(f1_scores, p_adjust = 'sidak').round(4)\n",
    "print(f1_df.style.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "123ab045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrr}\n",
      " & 1 & 2 & 3 & 4 & 5 & 6 & 7 \\\\\n",
      "1 & 1.000000 & 0.980800 & 0.139100 & 0.000000 & 0.000000 & 0.001100 & 0.000000 \\\\\n",
      "2 & 0.980800 & 1.000000 & 0.986400 & 0.000000 & 0.000000 & 0.148600 & 0.000800 \\\\\n",
      "3 & 0.139100 & 0.986400 & 1.000000 & 0.000100 & 0.000000 & 0.984200 & 0.103900 \\\\\n",
      "4 & 0.000000 & 0.000000 & 0.000100 & 1.000000 & 1.000000 & 0.023500 & 0.787700 \\\\\n",
      "5 & 0.000000 & 0.000000 & 0.000000 & 1.000000 & 1.000000 & 0.012900 & 0.648500 \\\\\n",
      "6 & 0.001100 & 0.148600 & 0.984200 & 0.023500 & 0.012900 & 1.000000 & 0.964400 \\\\\n",
      "7 & 0.000000 & 0.000800 & 0.103900 & 0.787700 & 0.648500 & 0.964400 & 1.000000 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc_df = scikit_posthocs.posthoc_dunn(accuracies, p_adjust = 'sidak').round(4)\n",
    "print(acc_df.style.to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
